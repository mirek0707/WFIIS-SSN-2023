{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratorium 2 - Convolutional Neural Network cz. II"
      ],
      "metadata": {
        "id": "-AWaFj8pE2wO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Zadanie 1* - Convolutional Neural Network (Max 1h 15min):\n",
        "\n",
        "**Zaimplementuj** model Convolutional Neural Networks (CNNs) do klasyfikacji:\n",
        "\n",
        "* Reuters\n",
        "* IMDB\n",
        "* Boston Housing price\n",
        "\n",
        "Wszystkie wspomniane zbiory danych znajduja się module Datasets Keras."
      ],
      "metadata": {
        "id": "55gxLwAHN1xl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dla datasetu Reuters może przydac sie poniższa implemtacja. Zapoznaj się z nia i dowiedz czym sa warstwy:\n",
        "* Conv1D,\n",
        "* Embedding,\n",
        "* GlobalMaxPooling1D.\n",
        "\n",
        "Czym jest **Tokenizer**? \n",
        "\n",
        "```\n",
        "# Load the Reuters dataset\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=10000)\n",
        "\n",
        "# Convert the data to one-hot encoding\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "X_train = tokenizer.sequences_to_matrix(X_train, mode='binary')\n",
        "X_test = tokenizer.sequences_to_matrix(X_test, mode='binary')\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 128, input_length=10000))\n",
        "model.add(Conv1D(64, 3, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(46, activation='softmax'))\n",
        "```\n",
        "\n",
        "Natomiast w przypadku IMDB przydać się możę coś podobnego:\n",
        "\n",
        "```\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the IMDB dataset and keep only the top 5000 most frequent words\n",
        "word_index = imdb.get_word_index()\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "# Pad sequences to the same length\n",
        "max_review_length = 500\n",
        "X_train = pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = pad_sequences(X_test, maxlen=max_review_length)\n",
        "\n",
        "```\n",
        "\n",
        "Czym jest **pad_sequences** ?"
      ],
      "metadata": {
        "id": "f_lEzrVeO9QH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autoenkodery"
      ],
      "metadata": {
        "id": "UkGbjfSmNvVZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autokodery**, zwane również autoenkoderami, pobierają dane wejściowe, przekształcają je w pewną reprezentację wewnętrzną, a następnie odtwarzają wynik przypominający dane wejściowe. Dokładniej, autoenkodery odnoszą się do sieci neuronowych, które potrafią uczyć się reprezentacji danych wejściowych (kodowania).\n",
        "\n",
        "Autoenkodery zawsze składają się z dwóch elementów:\n",
        "\n",
        "* kodera, który przekształca dane wejściowe do postaci reprezentacji,\n",
        "* dekodera, który przekształca dane z postaci reprezentacji na dane wyjściowe."
      ],
      "metadata": {
        "id": "5VlTeUXOCnWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoenkodery to rodzaj sztucznych sieci neuronowych, które są zdolne do nauki reprezentacji danych wejściowych. Najczęściej wyróżnia się dwa rodzaje autoenkoderów - niedopełniony i przepełniony. **Niedopełniony autoenkoder** ma mniej warstw ukrytych niż liczba danych wejściowych. To wymusza na nim znalezienie innej reprezentacji danych, ponieważ nie może po prostu skopiować i przekazać dalej danych wejściowych. **Przepełniony autoenkoder** ma więcej warstw ukrytych niż liczba danych wejściowych. Dzięki temu może uzyskać więcej cech. Jednak, w takim przypadku autoenkoder może się nauczyć po prostu przekazywać dane do kolejnych węzłów ukrytych, pomijając wiele innych, co uniemożliwia dodatkową ekstrakcję cech.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XX4u3C27CsJH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podział autoenkoderów:\n",
        "\n",
        "* Autoenkodery stosowe lub głębokie\n",
        "\n",
        "Autoenkodery, podobnie jak sieci neuronowe, mogą składać się z wielu warstw ukrytych. Dodawanie kolejnych warstw ma na celu wyuczenie modelu bardziej skomplikowanych zależności i kodowań. W przypadku głębokich autoenkoderów najczęściej stosuje się symetryczną architekturę, zwana \"kanapką\", zmniejszając kolejną liczbę warstw ukrytych o połowę.\n",
        "\n",
        "* Autoenkodery odszumiające (ang. denoising autoencoders)\n",
        "\n",
        "Inną ciekawą metodą do wydobywania cech i uniknięcia nadmiernego dopasowania autoenkodera do danych jest dodanie szumu lub zamaskowanie niektórych wartości wejściowych w sposób stochastyczny. Następnie model jest trenowany do odzyskiwania oryginalnych danych wejściowych (uwaga: tych nieuszkodzonych bez dodanego szumu). Pierwsze koncepcje wykorzystywania autoenkoderów do odszumiania pochodzą z lat 80. Bardziej znana jest jednak praca naukowa Pascala Vincenta z Uniwersytetu w Montrealu w Kanadzie, który w 2008 roku pokazał, że autoenkodery są świetnym narzędziem do wydobywania cech.\n",
        "\n",
        "* Autoenkodery rzadkie (ang. sparse autoencoders)\n",
        "\n",
        "Rzadkie autoenkodery nakładają ograniczenie na funkcję aktywacji warstw ukrytych, aby uniknąć nadmiernego dopasowania i poprawić odporność. Ten rodzaj autoenkodera pozwala na aktywację tylko niewielkiej liczby jednostek w ukrytej warstwie w tym samym czasie. Innymi słowy, jeden ukryty neuron powinien być nieaktywny przez większość czasu.\n",
        "\n",
        "* Autoenkodery kurczliwe (ang. contractive autoencoders)\n",
        "\n",
        "Podobnie jak rzadkie autoenkodery, modyfikują funkcję straty, ale w ten sposób, aby ukarać reprezentację, która jest zbyt wrażliwa na dane wejściowe. Tym samym poprawia odporność na małe zaburzenia wokół punktów danych treningowych. Innymi słowy, dwa podobne do siebie przykłady wejściowe muszą mieć podobne kodowanie.\n",
        "\n",
        "* Autoenkodery wariacyjne (ang. variational autoencoders)\n",
        "\n",
        "VAE należą do klasy autoenkoderów generatywnych, czyli takich, które umieją tworzyć nowe dane przypominające te w zbiorze uczącym. Dodatkowo VAE są autoenkoderami probabilistycznymi, czyli generują częściowo losowe wyniki nawet po wyuczeniu modelu. Powiedziałbym, że mają standardową architekturę autoenkoderów: po koderze składającym się często z kilku warstw ukrytych mamy dekoder. Natomiast mamy tutaj drobną zmianę: koder nie generuje bezpośrednio nas"
      ],
      "metadata": {
        "id": "0eMFdoWbC1SX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Przykładowe implementacje Autoenkoderów"
      ],
      "metadata": {
        "id": "Dtv1LaoHNYvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoenkodery stosowe lub głęboki"
      ],
      "metadata": {
        "id": "Y4rqFwN1E8MP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "# Wymiary obrazków MNIST\n",
        "input_dim = 784\n",
        "\n",
        "# Wyznaczamy wymiary warstw kodera i dekodera\n",
        "encoding_dim1 = 256\n",
        "encoding_dim2 = 128\n",
        "encoding_dim3 = 64\n",
        "\n",
        "# Definiujemy warstwy kodera\n",
        "input_img = Input(shape=(input_dim,))\n",
        "encoded = Dense(encoding_dim1, activation='relu')(input_img)\n",
        "encoded = Dense(encoding_dim2, activation='relu')(encoded)\n",
        "encoded = Dense(encoding_dim3, activation='relu')(encoded)\n",
        "\n",
        "# Definiujemy warstwy dekodera\n",
        "decoded = Dense(encoding_dim2, activation='relu')(encoded)\n",
        "decoded = Dense(encoding_dim1, activation='relu')(decoded)\n",
        "decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
        "\n",
        "# Tworzymy model autoenkodera\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Kompilujemy model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Wczytujemy zbiór danych MNIST\n",
        "from keras.datasets import mnist\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalizujemy dane i przekształcamy na wektor\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "# Trenujemy model\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "# Wizualizacja wyników\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Zastosuj model na zestawie testowym\n",
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "# Wypisz kilka obrazków testowych i odpowiadające im dekodowane wersje\n",
        "n = 10  # Ile obrazków chcesz wyświetlić\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Obrazek testowy\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Dekodowana wersja obrazka\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n",
        "```"
      ],
      "metadata": {
        "id": "UsMbzIeUFuLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoenkodery odszumiające (ang. denoising autoencoders)"
      ],
      "metadata": {
        "id": "5G-x2sxXFCio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "# Wymiary obrazków MNIST\n",
        "input_dim = 784\n",
        "\n",
        "# Wyznaczamy wymiary warstw kodera i dekodera\n",
        "encoding_dim1 = 256\n",
        "encoding_dim2 = 128\n",
        "encoding_dim3 = 64\n",
        "\n",
        "# Definiujemy warstwy kodera\n",
        "input_img = Input(shape=(input_dim,))\n",
        "encoded = Dense(encoding_dim1, activation='relu')(input_img)\n",
        "encoded = Dense(encoding_dim2, activation='relu')(encoded)\n",
        "encoded = Dense(encoding_dim3, activation='relu')(encoded)\n",
        "\n",
        "# Definiujemy warstwy dekodera\n",
        "decoded = Dense(encoding_dim2, activation='relu')(encoded)\n",
        "decoded = Dense(encoding_dim1, activation='relu')(decoded)\n",
        "decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
        "\n",
        "# Tworzymy model autoenkodera\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Kompilujemy model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Wczytujemy zbiór danych MNIST\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalizujemy i przekształcamy dane\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Dodajemy szum gaussowski do obrazków\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "\n",
        "# Przekształcamy dane na wektory\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "x_train_noisy = x_train_noisy.reshape((len(x_train_noisy), np.prod(x_train_noisy.shape[1:])))\n",
        "x_test_noisy = x_test_noisy.reshape((len(x_test_noisy), np.prod(x_test_noisy.shape[1:])))\n",
        "\n",
        "# Trenujemy model na danych z szumem\n",
        "autoencoder.fit(x_train_noisy, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test_noisy, x_test))\n",
        "\n",
        "# Wizualizacja wyników\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Zastosuj model na zestawie testowym\n",
        "decoded_imgs = autoencoder.predict(x_test_noisy)\n",
        "\n",
        "# Wypisz kilka obrazków testowych i odpowiadające im dekodowane wersje\n",
        "n = 10  # Ile obrazków chcesz wyświetlić\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Obrazek testowy\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Odpowiadający mu obrazek zdekodowany przez model\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "plt.show()\n",
        "```"
      ],
      "metadata": {
        "id": "b46WkXm1FvzM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoenkodery rzadkie (ang. sparse autoencoders)"
      ],
      "metadata": {
        "id": "BeY3go3xFClr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras import regularizers\n",
        "import numpy as np\n",
        "\n",
        "# Wymiary obrazków MNIST\n",
        "input_dim = 784\n",
        "\n",
        "# Wyznaczamy wymiary warstw kodera i dekodera\n",
        "encoding_dim1 = 256\n",
        "encoding_dim2 = 128\n",
        "encoding_dim3 = 64\n",
        "\n",
        "# Parametr regularyzacji rzadkości\n",
        "sparsity_factor = 0.1\n",
        "\n",
        "# Definiujemy warstwy kodera\n",
        "input_img = Input(shape=(input_dim,))\n",
        "encoded = Dense(encoding_dim1, activation='relu', activity_regularizer=regularizers.l1(sparsity_factor))(input_img)\n",
        "encoded = Dense(encoding_dim2, activation='relu', activity_regularizer=regularizers.l1(sparsity_factor))(encoded)\n",
        "encoded = Dense(encoding_dim3, activation='relu', activity_regularizer=regularizers.l1(sparsity_factor))(encoded)\n",
        "\n",
        "# Definiujemy warstwy dekodera\n",
        "decoded = Dense(encoding_dim2, activation='relu')(encoded)\n",
        "decoded = Dense(encoding_dim1, activation='relu')(decoded)\n",
        "decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
        "\n",
        "# Tworzymy model autoenkodera\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Kompilujemy model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Wczytujemy zbiór danych MNIST\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalizujemy i przekształcamy dane\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "# Trenujemy model\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "# Wizualizacja wyników\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Zastosuj model na zestawie testowym\n",
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "# Wypisz kilka obrazków testowych i odpowiadające im dekodowane wersje\n",
        "n = 10  # Ile obrazków chcesz wyświetlić\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Obrazek testowy\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Odpowiadający mu obrazek zdekodowany przez model\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "plt.show()\n",
        "```"
      ],
      "metadata": {
        "id": "p_bAAWJfFwyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoenkodery kurczliwe (ang. contractive autoencoders)\n",
        "\n"
      ],
      "metadata": {
        "id": "-mGtqZkNFCrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST dataset\n",
        "from keras.datasets import mnist\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize and flatten input data\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "# Define contractive autoencoder model\n",
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(128, activation='relu', activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# Create model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Compile model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train model\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=10,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "# Encode and decode test set\n",
        "encoded_imgs = autoencoder.predict(x_test)\n",
        "```"
      ],
      "metadata": {
        "id": "uCYJL5muFxct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoenkodery wariacyjne (ang. variational autoencoders)\n"
      ],
      "metadata": {
        "id": "lhQsDpVmFY98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "\n",
        "# Define the dimensions of the latent space\n",
        "latent_dim = 2\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (784,)\n",
        "\n",
        "# Define the encoder architecture\n",
        "input_layer = Input(shape=input_shape)\n",
        "hidden_layer = Dense(512, activation='relu')(input_layer)\n",
        "z_mean = Dense(latent_dim)(hidden_layer)\n",
        "z_log_var = Dense(latent_dim)(hidden_layer)\n",
        "\n",
        "# Define the sampling function\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "# Use the sampling function to sample from the latent space\n",
        "z = Lambda(sampling)([z_mean, z_log_var])\n",
        "\n",
        "# Define the decoder architecture\n",
        "decoder_input = Input(shape=(latent_dim,))\n",
        "decoder_hidden = Dense(512, activation='relu')(decoder_input)\n",
        "decoder_output = Dense(784, activation='sigmoid')(decoder_hidden)\n",
        "\n",
        "# Define the models\n",
        "encoder = Model(input_layer, [z_mean, z_log_var, z], name='encoder')\n",
        "decoder = Model(decoder_input, decoder_output, name='decoder')\n",
        "vae_output = decoder(encoder(input_layer)[2])\n",
        "vae = Model(input_layer, vae_output, name='vae')\n",
        "\n",
        "# Define the loss function\n",
        "reconstruction_loss = binary_crossentropy(input_layer, vae_output)\n",
        "kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "\n",
        "# Compile the model\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.reshape(x_train.shape[0], np.prod(x_train.shape[1:]))\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.reshape(x_test.shape[0], np.prod(x_test.shape[1:]))\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Train the model\n",
        "vae.fit(x_train, epochs=2, batch_size=128, validation_data=(x_test, None))\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_vae_results(vae, x_test):\n",
        "    # Encode the test images\n",
        "    encoder = vae.get_layer('encoder')\n",
        "    z_mean, _, _ = encoder.predict(x_test)\n",
        "\n",
        "    # Generate new images by sampling from the learned distribution\n",
        "    decoder = vae.get_layer('decoder')\n",
        "    n = 15  # number of images to generate\n",
        "    digit_size = 28\n",
        "    figure = np.zeros((digit_size * n, digit_size * n))\n",
        "\n",
        "    # Sample from the learned distribution\n",
        "    grid_x = np.linspace(-4, 4, n)\n",
        "    grid_y = np.linspace(-4, 4, n)[::-1]\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "            z_sample = np.array([[xi, yi]])\n",
        "            x_decoded = decoder.predict(z_sample)\n",
        "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "            figure[i * digit_size: (i + 1) * digit_size,\n",
        "                   j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "    # Plot the generated images\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(figure, cmap='Greys_r')\n",
        "    plt.show()\n",
        "\n",
        "# Generate and display new images\n",
        "display_vae_results(vae, x_test)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "jVpXggIPJMUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Zadanie 2* - Podstawy Autoenkoderów (Max 1h 15min):\n",
        "\n",
        "**Zaimplementuj** wszysytkie typy autoenkoderów dla zbioru danych:\n",
        "\n",
        "* CIFAR-10 (wykorzystaj wbudowany modul z biblioteki Keras)\n",
        "\n",
        "Wykorzystaj inne Optymalizatory oraz bardziej zaawansowana architekture niż w przykładach. Jak należy interpretować osiagniete wyniki dla CIFAR-10? W celu zrozumienia autoencoderów zapoznaj się z załaczonymi materiałami."
      ],
      "metadata": {
        "id": "_pcnm1ZzStIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Materiały"
      ],
      "metadata": {
        "id": "_UmhN_XrFcBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoenkodery:\n",
        "* https://www.unite.ai/what-is-an-autoencoder/ (wraz z rodzajami) \n",
        "* https://www.tensorflow.org/tutorials/generative/autoencoder\n",
        "* https://www.mygreatlearning.com/blog/autoencoder/ \n",
        "* https://towardsdatascience.com/auto-encoder-what-is-it-and-what-is-it-used-for-part-1-3e5c6f017726 \n",
        "* https://iq.opengenus.org/types-of-autoencoder/\n",
        "* https://www.jeremyjordan.me/autoencoders/ \n",
        "* https://www.deeplearningbook.org/contents/autoencoders.html\n",
        "* https://www.mygreatlearning.com/blog/autoencoder/\n",
        "* https://www.tensorflow.org/tutorials/generative/autoencoder?hl=pl\n",
        "* https://medium.com/pytorch/implementing-an-autoencoder-in-pytorch-19baa22647d1\n",
        "* https://www.tutorialspoint.com/how-to-implementing-an-autoencoder-in-pytorch\n",
        "* https://github.com/AlexPasqua/Autoencoders \n",
        "\n",
        "Youtube:\n",
        "\n",
        "* https://www.youtube.com/watch?v=JoR5HCs0n0s\n",
        "* https://www.youtube.com/watch?v=1h-KUgGSrsk \n",
        "* https://www.youtube.com/watch?v=8wrLjnQ7EWQ"
      ],
      "metadata": {
        "id": "KvEf71_6BQsX"
      }
    }
  ]
}